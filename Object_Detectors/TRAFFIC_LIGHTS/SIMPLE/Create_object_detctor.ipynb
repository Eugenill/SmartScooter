{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Bosch_TL_DATASET.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-xii0ptVzzaH","colab_type":"text"},"source":["#TRAFFIC LIGHT & COLOR DETECTION\n","\n","\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JzrkNOV2cmO7","colab_type":"text"},"source":["##Setup installation\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6_2lH-3TcpqC","colab_type":"text"},"source":["###TensorFlow version = 1.X"]},{"cell_type":"code","metadata":{"id":"ruysrCqALMSm","colab_type":"code","colab":{}},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__) "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"W43mvuw9LyON","colab_type":"text"},"source":["###Restart RUNTIME after selected version of tensorflow in case of failure or Restart"]},{"cell_type":"code","metadata":{"id":"OgOfZuv8LrBH","colab_type":"code","colab":{}},"source":["import os\n","os.kill(os.getpid(), 9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"naGDfJ2rMZaF","colab_type":"text"},"source":["###Mount drive (Every Time)"]},{"cell_type":"code","metadata":{"id":"VRBZO3g-MFVX","colab_type":"code","outputId":"10274663-4f69-4d41-be65-1a70a4f1cc8e","executionInfo":{"status":"ok","timestamp":1584990817465,"user_tz":-60,"elapsed":25880,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"4OZUiSW2MtNf","colab_type":"text"},"source":["###Clone the Tensorflow models repository and the SmartScooter repo from github (Just 1 Time)"]},{"cell_type":"markdown","metadata":{"id":"hCP1hy8eMefa","colab_type":"text"},"source":["Change directory to SMART_SCOOTER"]},{"cell_type":"code","metadata":{"id":"T9cy_cJfMe9L","colab_type":"code","colab":{}},"source":["%cd '/content/drive/My Drive/SMART_SCOOTER/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BkDXUBicMuci","colab_type":"code","colab":{}},"source":["!git clone https://github.com/tensorflow/models.git\n","!git clone https://github.com/Eugenill/SmartScooter.git\n","!cp -r pycocotools /content/models/research/"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBdmV_6uM1Xb","colab_type":"text"},"source":["###Install needed libraries\n"]},{"cell_type":"code","metadata":{"id":"niSH0OtgM1dr","colab_type":"code","colab":{}},"source":["%cd '/content/drive/My Drive/SMART_SCOOTER/'\n","#1. Install some needed tools\n","!apt-get install protobuf-compiler python-pil python-lxml python-tk\n","!pip install Cython\n","#2. Compile the model definitionn\n","%cd /content/drive/My Drive/SMART_SCOOTER/models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","#3. Set the environment\n","import os\n","os.environ['PYTHONPATH'] += ':/content/drive/My Drive/SMART_SCOOTER/models/research/:/content/drive/My Drive/SMART_SCOOTER/models/research/slim'\n","#4. Always run this every restart of session\n","!python setup.py build\n","!python setup.py install\n","#5. Test to see if all we need for the training has been installed\n","!python object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FeRXMKSROf7D","colab_type":"text"},"source":["##Prepare images and annotations\n","\n","\n","---\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"I9OVHkbzdksX","colab_type":"text"},"source":["###Import images "]},{"cell_type":"markdown","metadata":{"id":"sGGvCpkKdr5N","colab_type":"text"},"source":["Save the images in `SMART_SCOOTER/images/folder_name`"]},{"cell_type":"markdown","metadata":{"id":"w7J-pp9ssoAW","colab_type":"text"},"source":["###Import annotations"]},{"cell_type":"markdown","metadata":{"id":"tz4H_Ly8srXj","colab_type":"text"},"source":["####Pascal format (.xml) - Other traffic light images"]},{"cell_type":"markdown","metadata":{"id":"2D5zu44psz61","colab_type":"text"},"source":["Save the image xml annotations in `SMART_SCOOTER/train_xml_annotations or test_xml_annotations `"]},{"cell_type":"markdown","metadata":{"id":"tQGWQej4tOO2","colab_type":"text"},"source":["Remember to specify the path to the image in **filename**, but just from the SMART_SCOOTER/images/ folder.\n","\n","EXAMPLE\n","```\n","<annotation>\n","\t<folder></folder>\n","\t<filename>rgb_jpg/train/.....</filename>\n","\t<path></path>\n","\t<source>\n","\t\t<database>Unknown</database>\n","\t</source>\n","\t<size>\n","\t\t<width>300</width>\n","\t\t<height>300</height>\n","\t\t<depth>3</depth>\n","\t</size>\n","\t<segmented>0</segmented>\n","\t<object>\n","\t\t<name>cone</name>\n","\t\t<pose>Unspecified</pose>\n","\t\t<truncated>0</truncated>\n","\t\t<difficult>0</difficult>\n","\t\t<bndbox>\n","\t\t\t<xmin>300</xmin>\n","\t\t\t<ymin>200</ymin>\n","\t\t\t<xmax>310</xmax>\n","\t\t\t<ymax>210</ymax>\n","\t\t</bndbox>\n","\t</object>\n","</annotation>\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3Q7j2C1o5fY2","colab_type":"text"},"source":["We will copy the xml annotations to `SMART_SCOOTER/annotations/TL/train_xml_annotations/` and create the `test_xml_annotations` folder too"]},{"cell_type":"code","metadata":{"id":"U1Jw3HrF6Cic","colab_type":"code","colab":{}},"source":["%cd '/content/drive/My Drive/SMART_SCOOTER/annotations/TL'\n","%cp new_train_xml train_xml_annotations\n","%mkdir test_xml_annotations"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6CfYNak8uTSa","colab_type":"text"},"source":["#### Bosch format (.yaml)"]},{"cell_type":"markdown","metadata":{"id":"xbF1mRfEuZNZ","colab_type":"text"},"source":["To use this annotations we first have to convert the train and test.yaml to xml files that we are going to save in the same folder as the the ones we already have saved.\n","In: `train and test_xml_annotations`\n","\n","\n","\n","We have the yaml's in `SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/label_files`"]},{"cell_type":"markdown","metadata":{"id":"SfTHkcf_Rfwm","colab_type":"text"},"source":["\n","\n","```\n","#-------------NEW\n","\tonlypath=impath.split('./')[1]\n","\tsecond_folder=onlypath.split('/').[1]\n","\timagename = impath.split('/')[-1]\n","\tpath_w_noimage=onlypath.split(imagename)[0]\n","\tcurrentfolder = savedir.split(\"\\\\\")[-1]\n","\tif 'train' in onlypath:\t\t\n","\t\tif second_folder not in os.listdir(\"/content/drive/My Drive/SMART_SCOOTER/images/rgb_jpg/train\"): \n","\t\t\tos.mkdir(\"/content/drive/My Drive/SMART_SCOOTER/images/rgb_jpg/train/\"+second_folder)\n","\tif imagename in os.listdir(\"/content/drive/My Drive/SMART_SCOOTER/images/\"+path_w_noimage):\n","#--------------\n","\n","```\n","\n","- In one hand we have to create those folders of images we dont have in our drive, but we have their annotation (just to not get errors).\n","\n","- Secondly we are just going to create those xml of the images we have in our image folders.\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tvlQmP6JBhoF","colab_type":"text"},"source":["INPUTS: \n","1. yaml files\n","\n","OUTPUT:\n","1. Xml annotations saved in the folder specified"]},{"cell_type":"code","metadata":{"id":"HdJMO7TSRCak","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS\n","!python bosch_to_pascal.py 'label_files/train.yaml' '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/train_xml_annotations/'\n","!python bosch_to_pascal.py 'label_files/test.yaml' '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/test_xml_annotations/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"B1AcmvIV7d3j","colab_type":"text"},"source":["###Create csv files"]},{"cell_type":"markdown","metadata":{"id":"ddbhuxotUXl-","colab_type":"text"},"source":["Change paths to search the xml and to save the csv files in `xml_to_csv.py` : \n","\n","```\n","def main():\n","  for folder in ['train', 'test']:\n","        image_path = os.path.join(os.getcwd(), ('/content/drive/My Drive/SMART_SCOOTER/annotations/TL/'+folder+'_xml_annotations'))\n","        xml_df = xml_to_csv(image_path)\n","        xml_df.to_csv(('/content/drive/My Drive/SMART_SCOOTER/annotations/TL/'+folder+'_csv_annotations/'+folder+'_labels.csv'), index=None)\n","  print('Successfully converted xml to csv.')\n","\n","```\n","  \n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aN5RVCMi-bBu"},"source":["This script was originally from: https://github.com/datitran/raccoon_dataset"]},{"cell_type":"code","metadata":{"id":"s2p08r2hRg1L","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS\n","!python xml_to_csv.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"R0Txy7Jn8ZCu","colab_type":"text"},"source":["##Create train and test.record\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Okvfg7fY97F8","colab_type":"text"},"source":["To create the record files we have to use `generate_tfrecord.py` already downloaded and modified.  "]},{"cell_type":"markdown","metadata":{"id":"TKm9TuZP0tBe","colab_type":"text"},"source":["\n","The .records are files that collects all those images labeled (empty or not) in an 'array' with: `filename (and its folder), height, weigth, class, and position of the object box`. FOR EVERY IMAGE LABELED ONLY.\n","\n","The .record's are the only files that contains information of the dataset for the training.\n"]},{"cell_type":"markdown","metadata":{"id":"kvKu2JKfWk9z","colab_type":"text"},"source":["Modifications:\n","\n","```\n","def class_text_to_int(row_label):\n","    if row_label == 'Off':\n","        return 1\n","    elif row_label == 'Green':\n","        return 2\n","    elif row_label == 'Yellow':\n","        return 3\n","    elif row_label == 'Red':\n","        return 4\n","    else:\n","        return 0\n","```\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g9C1hVwv-S2f"},"source":["This script was originally from: https://github.com/datitran/raccoon_dataset"]},{"cell_type":"markdown","metadata":{"id":"Lh7jnOeGBRzK","colab_type":"text"},"source":["INPUTS: \n","1. CSV files\n","2. Image principal folder\n","\n","OUTPUT:\n","1. record file, saved in ../record/"]},{"cell_type":"code","metadata":{"id":"nSajdNJnYTfE","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS\n","!python generate_tfrecord.py --csv_input='/content/drive/My Drive/SMART_SCOOTER/annotations/TL/train_csv_annotations/train_labels.csv' --image_dir='/content/drive/My Drive/SMART_SCOOTER/images' --output_path='/content/drive/My Drive/SMART_SCOOTER/record_files/train.record'\n","!python generate_tfrecord.py --csv_input='/content/drive/My Drive/SMART_SCOOTER/annotations/TL/test_csv_annotations/test_labels.csv' --image_dir='/content/drive/My Drive/SMART_SCOOTER/images' --output_path='/content/drive/My Drive/SMART_SCOOTER/record_files/test.record'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RyIMLmYA-kiL","colab_type":"text"},"source":["##Create labelmap, ckpt and config files\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"95MYGTJECDF1","colab_type":"text"},"source":["###Labelmap.pbtxt"]},{"cell_type":"markdown","metadata":{"id":"0bI9YpC6CGoh","colab_type":"text"},"source":["This file tells the training which labels (classes) we want as output in the model. We are going to \"attach\" this file in the config"]},{"cell_type":"markdown","metadata":{"id":"JhKIqwkTCYRO","colab_type":"text"},"source":["We find this file in: ```SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/labelmap```\n","\n","\n","```\n","item {\n","  id: 1\n","  name: 'off'\n","}\n","\n","item {\n","  id: 2\n","  name: 'Green'\n","}\n","\n","item {\n","  id: 3\n","  name: 'Yellow'\n","}\n","\n","item {\n","  id: 4\n","  name: 'Red'\n","}\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mCMIMwMjDKgY","colab_type":"text"},"source":["###model.ckpt"]},{"cell_type":"markdown","metadata":{"id":"BvaOtaaokDM6","colab_type":"text"},"source":["We can download any pre-trained Object detection model from tensorflow with the code below. In this case we are downloading the ssdlite_mobilenet_v2"]},{"cell_type":"code","metadata":{"id":"m61blLNHkEqC","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/\n","!wget http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\n","!tar -xvf ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_LZUGf7lBI3c","colab_type":"text"},"source":["From this downloaded model we will use the pretrained model: \n","```model.ckpt```\n","This model has two parts:\n","1. Mobilenet for feature extraction model\n","2. SSDlite_v2 for finetuning\n","\n","In the training process we will import all the pretrained mobilenet part, and we will modify the SSD part (finetunning).\n"]},{"cell_type":"markdown","metadata":{"id":"V59esfQpC-fw","colab_type":"text"},"source":["###Config"]},{"cell_type":"markdown","metadata":{"id":"xP3Ik6oTsLI_","colab_type":"text"},"source":["The config file tells the training how we are going to train the model and with which files.\n","\n","In this case the config file is also originally from the ssdlite_mobilenet_v2 model. But with the next modifications:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ClhsOPMcpd0f","colab_type":"text"},"source":["1. `num_classes=4`\n","\n","2. `set anchor boxes aspect ratios`\n","\n","3. `fine_tune_checkpoint: \"/content/drive/My Drive/SMART_SCOOTER/ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt\"`\n","\n","  or\n","\n","  `fine_tune_checkpoint: \"/content/drive/My Drive/SMART_SCOOTER/new_models/TL_XX/model.ckpt-XXXX\"`\n","\n","3. `set batch_size=24`\n","\n","5. `num_steps=10000-15000`\n","\n","4. `input_path: \"/content/drive/My Drive/SMART_SCOOTER/record_files/train.record\"`\n","\n","5. `input_path: \"/content/drive/My Drive/SMART_SCOOTER/record_files/test.record\"`\n","\n","6. `label_map_path: \"/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/labelmap/TL.pbtxt\"`\n","\n","7. ```\n","image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","```\n","8. `num_examples: 1438 (test images)`\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"FmH5B8gpZYtQ","colab_type":"text"},"source":["We will find the config in: `SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config`"]},{"cell_type":"markdown","metadata":{"id":"4Kp8q-1PA0ot","colab_type":"text"},"source":["##Training\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9Dcy2OKfumnj","colab_type":"text"},"source":["Open your google drive tab and go to Legacy folder in the object detection directory, copy or move the train.py file into the object detection folder. then go back to Colab and run the training with the code below. train_dir (train.py), model_dir (model_main.py)"]},{"cell_type":"code","metadata":{"id":"2eFkrLiZV3mA","colab_type":"code","colab":{}},"source":["%tensorboard --logdir /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/training/TL_V1"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"zVZ0x484uqP6","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/\n","!python model_main.py --logtostderr --model_dir='/content/drive/My Drive/SMART_SCOOTER/training/TL_V2/' --pipeline_config_path='/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config/TL.config'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQ72Qg8XlYRQ","colab_type":"text"},"source":["##Export your inference graph\n","\n","---\n","\n"]},{"cell_type":"code","metadata":{"id":"00CU-oBHlYgd","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n","!python export_inference_graph.py --input_type image_tensor  --pipeline_config_path '/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config/TL.config'   --trained_checkpoint_prefix training/TL_V1/model.ckpt-15000   --output_directory new_models/TL_V1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Oed6NEhfox74","colab_type":"text"},"source":["Zip your inference saved on object_detection"]},{"cell_type":"code","metadata":{"id":"Luz9YZe5oyns","colab_type":"code","colab":{}},"source":["!zip -r TL_V1.zip new_models/TL_V1"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2fwi02fdrsdy","colab_type":"text"},"source":["Create files to run the network on opencv. \n","In other words, we need to create a graph.pbtxtt, but we already have it from the training itself"]},{"cell_type":"code","metadata":{"id":"dCcdtrqDr_Ei","colab_type":"code","colab":{}},"source":["!wget https://github.com/opencv/opencv/blob/master/samples/dnn/tf_text_graph_ssd.py\n","!wget https://github.com/opencv/opencv/blob/master/samples/dnn/tf_text_graph_common.py"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"1ELaYAZPo_4p","colab_type":"code","outputId":"133ae77e-666d-405e-fd1d-c21a3fd6048d","executionInfo":{"status":"ok","timestamp":1584638133739,"user_tz":-60,"elapsed":8066,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":153}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/\n","!python tf_text_graph_ssd.py --input new_models/TL_V1/frozen_inference_graph.pb --config training/TL_V1/TL_V1.config --output new_models/TL_V1/graph.pbtxt"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n","Scale: [0.200000-0.950000]\n","Aspect ratios: [1.0, 2.0, 0.5, 3.0, 0.3333]\n","Reduce boxes in the lowest layer: True\n","Number of classes: 4\n","Number of layers: 6\n","box predictor: convolutional\n","Input image size: 300x300\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"oVp3Ti0iofug","colab_type":"text"},"source":["##Test your inference graph\n","\n","---\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DZ9K_ofDyrE6","colab_type":"code","outputId":"ef11a243-4350-40ef-8aa0-0d043023cbd0","executionInfo":{"status":"ok","timestamp":1584624174230,"user_tz":-60,"elapsed":1367,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4kFYqGw89qS2","colab_type":"code","outputId":"563ac200-eca6-48f5-dc75-6c6db9a66c25","executionInfo":{"status":"ok","timestamp":1584625481304,"user_tz":-60,"elapsed":799,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/utils\n","# This is needed since the notebook is stored in the object_detection folder.\n","\n","sys.path.append(\"..\")\n","import utils\n","#sys.path.append(\"..\")\n","import label_map_util\n","\n","import visualization_utils as vis_util"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jo1zLXX4uKW5","colab_type":"code","outputId":"9d6d6437-80e2-43d9-da0e-0d476bb088b0","executionInfo":{"status":"ok","timestamp":1584625597000,"user_tz":-60,"elapsed":23338,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"output_embedded_package_id":"1XWupKtXQAx9AHI_9HcoJeSvvj1kUiJ4a"}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = '/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/new_models/TL_V1/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = os.path.join('/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/training/TL_V1', 'TL_V1.pbtxt')\n","\n","NUM_CLASSES = 4\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n","PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/images/rgb_jpg/train/2015-10-05-14-40-46_bag'\n","TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}'.format(i)) for i in os.listdir('/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/images/rgb_jpg/train/2015-10-05-14-40-46_bag') ]\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","c=0\n","with detection_graph.as_default():\n","    with tf.Session(graph=detection_graph) as sess:\n","        # Definite input and output Tensors for detection_graph\n","        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","        # Each box represents a part of the image where a particular object was detected.\n","        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","        # Each score represent how level of confidence for each of the objects.\n","        # Score is shown on the result image, together with the class label.\n","        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n","        for image_path in TEST_IMAGE_PATHS:\n","         if c<6: \n","          if image_path.endswith('.jpg'):\n","            image = Image.open(image_path)\n","            # the array based representation of the image will be used later in order to prepare the\n","            # result image with boxes and labels on it.\n","            image_np = load_image_into_numpy_array(image)\n","            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","            image_np_expanded = np.expand_dims(image_np, axis=0)\n","            # Actual detection.\n","            (boxes, scores, classes, num) = sess.run(\n","                [detection_boxes, detection_scores, detection_classes, num_detections],\n","                feed_dict={image_tensor: image_np_expanded})\n","            # Visualization of the results of a detection.\n","            vis_util.visualize_boxes_and_labels_on_image_array(\n","                image_np,\n","                np.squeeze(boxes),\n","                np.squeeze(classes).astype(np.int32),\n","                np.squeeze(scores),\n","                category_index,\n","                use_normalized_coordinates=True,\n","                line_thickness=8)\n","            plt.figure(figsize=IMAGE_SIZE)\n","            plt.imshow(image_np)\n","            c+=1"],"execution_count":0,"outputs":[{"output_type":"display_data","data":{"text/plain":"Output hidden; open in https://colab.research.google.com to view."},"metadata":{}}]}]}