{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"TL object detector.ipynb","provenance":[],"collapsed_sections":["JzrkNOV2cmO7","FeRXMKSROf7D","I9OVHkbzdksX","w7J-pp9ssoAW","B1AcmvIV7d3j","R0Txy7Jn8ZCu","95MYGTJECDF1","mCMIMwMjDKgY"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"-xii0ptVzzaH","colab_type":"text"},"source":["#TRAFFIC LIGHT & COLOR DETECTION\n","\n","\n","\n","---\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"JzrkNOV2cmO7","colab_type":"text"},"source":["##Setup installation\n","\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"6_2lH-3TcpqC","colab_type":"text"},"source":["###TensorFlow version = 1.X"]},{"cell_type":"code","metadata":{"id":"ruysrCqALMSm","colab_type":"code","outputId":"598ab7f5-9129-4e53-96a2-917f5e41b349","executionInfo":{"status":"ok","timestamp":1585060826025,"user_tz":-60,"elapsed":1852,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%tensorflow_version 1.x\n","import tensorflow as tf\n","print(tf.__version__) "],"execution_count":0,"outputs":[{"output_type":"stream","text":["1.15.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"W43mvuw9LyON","colab_type":"text"},"source":["###Restart RUNTIME after selected version of tensorflow in case of failure or Restart"]},{"cell_type":"code","metadata":{"id":"OgOfZuv8LrBH","colab_type":"code","colab":{}},"source":["import os\n","os.kill(os.getpid(), 9)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"naGDfJ2rMZaF","colab_type":"text"},"source":["###Mount drive (Every Time)"]},{"cell_type":"code","metadata":{"id":"VRBZO3g-MFVX","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4OZUiSW2MtNf","colab_type":"text"},"source":["###Clone the Tensorflow models repository and the SmartScooter repo from github (Just 1 Time)"]},{"cell_type":"markdown","metadata":{"id":"hCP1hy8eMefa","colab_type":"text"},"source":["Change directory to SMART_SCOOTER"]},{"cell_type":"code","metadata":{"id":"BkDXUBicMuci","colab_type":"code","colab":{}},"source":["%cd '/content/drive/My Drive/SMART_SCOOTER/'\n","!git clone https://github.com/tensorflow/models.git"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Q19wV8fraFTe","colab_type":"text"},"source":["We need to clone the cocoapi repo to evaluate the model while training using model_main.py"]},{"cell_type":"code","metadata":{"id":"FyYq8wPeUYpb","colab_type":"code","colab":{}},"source":["%cd '/content/drive/My Drive/SMART_SCOOTER/'\n","!git clone https://github.com/cocodataset/cocoapi.git\n","!cd cocoapi/PythonAPI; make; cp -r pycocotools '/content/drive/My Drive/SMART_SCOOTER/models/research/'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"acOt9UR-BdH4","colab_type":"code","colab":{}},"source":["#remove and create it again\n","%cd '/content/drive/My Drive/SMART_SCOOTER/'\n","%rm -r -f SmartScooter/ \n","!git clone https://USERNAME:PASSW@github.com/Eugenill/SmartScooter.git"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZBdmV_6uM1Xb","colab_type":"text"},"source":["###Install needed libraries\n"]},{"cell_type":"code","metadata":{"id":"niSH0OtgM1dr","colab_type":"code","colab":{}},"source":["%cd '/content/drive/My Drive/SMART_SCOOTER/'\n","#1. Install some needed tools\n","!apt-get install protobuf-compiler python-pil python-lxml python-tk\n","!pip install Cython\n","#2. Compile the model definitionn\n","%cd /content/drive/My Drive/SMART_SCOOTER/models/research/\n","!protoc object_detection/protos/*.proto --python_out=.\n","#3. Set the environment\n","import os\n","os.environ['PYTHONPATH'] += ':/content/drive/My Drive/SMART_SCOOTER/models/research/:/content/drive/My Drive/SMART_SCOOTER/models/research/slim'\n","#4. Always run this every restart of session\n","!python setup.py build\n","!python setup.py install\n","#5. Test to see if all we need for the training has been installed\n","!python object_detection/builders/model_builder_test.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FeRXMKSROf7D","colab_type":"text"},"source":["##Prepare images and annotations\n","\n","\n","---\n","\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"I9OVHkbzdksX","colab_type":"text"},"source":["###Import images "]},{"cell_type":"markdown","metadata":{"id":"sGGvCpkKdr5N","colab_type":"text"},"source":["Save the images in `SMART_SCOOTER/images/folder_name`"]},{"cell_type":"markdown","metadata":{"id":"w7J-pp9ssoAW","colab_type":"text"},"source":["###Import annotations"]},{"cell_type":"markdown","metadata":{"id":"tz4H_Ly8srXj","colab_type":"text"},"source":["####Pascal format (.xml) - Other traffic light images"]},{"cell_type":"markdown","metadata":{"id":"2D5zu44psz61","colab_type":"text"},"source":["Save the image xml annotations in `SMART_SCOOTER/train_xml_annotations or test_xml_annotations `"]},{"cell_type":"markdown","metadata":{"id":"tQGWQej4tOO2","colab_type":"text"},"source":["Remember to specify the path to the image in **filename**, but just from the SMART_SCOOTER/images/ folder.\n","\n","EXAMPLE\n","```\n","<annotation>\n","\t<folder></folder>\n","\t<filename>rgb_jpg/train/.....</filename>\n","\t<path></path>\n","\t<source>\n","\t\t<database>Unknown</database>\n","\t</source>\n","\t<size>\n","\t\t<width>300</width>\n","\t\t<height>300</height>\n","\t\t<depth>3</depth>\n","\t</size>\n","\t<segmented>0</segmented>\n","\t<object>\n","\t\t<name>cone</name>\n","\t\t<pose>Unspecified</pose>\n","\t\t<truncated>0</truncated>\n","\t\t<difficult>0</difficult>\n","\t\t<bndbox>\n","\t\t\t<xmin>300</xmin>\n","\t\t\t<ymin>200</ymin>\n","\t\t\t<xmax>310</xmax>\n","\t\t\t<ymax>210</ymax>\n","\t\t</bndbox>\n","\t</object>\n","</annotation>\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"3Q7j2C1o5fY2","colab_type":"text"},"source":["We will move the xml annotations to `SMART_SCOOTER/annotations/TL/train_xml_annotations/` and create the `test_xml_annotations` folder too"]},{"cell_type":"code","metadata":{"id":"U1Jw3HrF6Cic","colab_type":"code","colab":{}},"source":["%mv '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/new_train_xml' '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/train_xml_annotations'\n","%mkdir test_xml_annotations"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"6CfYNak8uTSa","colab_type":"text"},"source":["#### Bosch format (.yaml)"]},{"cell_type":"markdown","metadata":{"id":"xbF1mRfEuZNZ","colab_type":"text"},"source":["To use this annotations we first have to convert the train and test.yaml to xml files that we are going to save in the same folder as the the ones we already have saved.\n","In: `train and test_xml_annotations`\n","\n","\n","\n","We have the yaml's in `SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/label_files`"]},{"cell_type":"markdown","metadata":{"id":"SfTHkcf_Rfwm","colab_type":"text"},"source":["\n","\n","```\n","#-------------NEW\n","\timpath = image['path'].replace('png','jpg').replace('rgb','rgb_jpg')\n","\tonlypath=impath.split('./')[1]\n","\tsecond_folder=onlypath.split('/')[2]\n","\timagename = impath.split('/')[-1]\n","\tpath_w_noimage=onlypath.split(imagename)[0]\n","\tcurrentfolder = savedir.split(\"\\\\\")[-1]\n","\tif 'train' in onlypath:\t\t\n","\t\tif second_folder not in os.listdir(\"/content/drive/My Drive/SMART_SCOOTER/images/TL/rgb_jpg/train\"): \n","\t\t\tos.mkdir(\"/content/drive/My Drive/SMART_SCOOTER/images/TL/rgb_jpg/train/\"+second_folder)\n","\tif imagename in os.listdir(\"/content/drive/My Drive/SMART_SCOOTER/images/TL/\"+path_w_noimage):\n","#--------------\n","\n","```\n","\n","- In one hand we have to create those folders of images we dont have in our drive, but we have their annotation (just to not get errors).\n","\n","- Secondly we are just going to create those xml of the images we have in our image folders.\n","\n","- We are also changing the path to th 'jpg' images and to the correct 'rgb_jpg' folder\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"tvlQmP6JBhoF","colab_type":"text"},"source":["INPUTS: \n","1. yaml files\n","\n","OUTPUT:\n","1. Xml annotations saved in the folder specified"]},{"cell_type":"code","metadata":{"id":"HdJMO7TSRCak","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS\n","!python bosch_to_pascal.py 'label_files/train.yaml' '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/train_xml_annotations/'\n","!python bosch_to_pascal.py 'label_files/test.yaml' '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/test_xml_annotations/'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"0U4yuNEWUf8r"},"source":["If already have this files and run this, files will be overwritten"]},{"cell_type":"markdown","metadata":{"id":"B1AcmvIV7d3j","colab_type":"text"},"source":["###Create csv files"]},{"cell_type":"markdown","metadata":{"id":"ddbhuxotUXl-","colab_type":"text"},"source":["Change paths to search the xml and to save the csv files in `xml_to_csv.py` : \n","\n","```\n","def main():\n","  for folder in ['train', 'test']:\n","        image_path = os.path.join(os.getcwd(), ('/content/drive/My Drive/SMART_SCOOTER/annotations/TL/'+folder+'_xml_annotations'))\n","        xml_df = xml_to_csv(image_path)\n","        xml_df.to_csv(('/content/drive/My Drive/SMART_SCOOTER/annotations/TL/'+folder+'_csv_annotations/'+folder+'_labels.csv'), index=None)\n","  print('Successfully converted xml to csv.')\n","\n","```\n","  \n","\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"aN5RVCMi-bBu"},"source":["This script was originally from: https://github.com/datitran/raccoon_dataset"]},{"cell_type":"code","metadata":{"id":"s2p08r2hRg1L","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS\n","%mkdir '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/train_csv_annotations'\n","%mkdir '/content/drive/My Drive/SMART_SCOOTER/annotations/TL/test_csv_annotations'\n","!python xml_to_csv.py"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"haBW5huMTif2","colab_type":"text"},"source":["If already have a csv files and run this, files will be overwritten"]},{"cell_type":"markdown","metadata":{"id":"R0Txy7Jn8ZCu","colab_type":"text"},"source":["##Create train and test.record\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Okvfg7fY97F8","colab_type":"text"},"source":["To create the record files we have to use `generate_tfrecord.py` already downloaded and modified.  "]},{"cell_type":"markdown","metadata":{"id":"TKm9TuZP0tBe","colab_type":"text"},"source":["\n","The .records are files that collects all those images labeled (empty or not) in an 'array' with: `filename (and its folder), height, weigth, class, and position of the object box`. FOR EVERY IMAGE LABELED ONLY.\n","\n","The .record's are the only files that contains information of the dataset for the training.\n"]},{"cell_type":"markdown","metadata":{"id":"kvKu2JKfWk9z","colab_type":"text"},"source":["Modifications:\n","\n","```\n","def class_text_to_int(row_label):\n","    if row_label == 'Off':\n","        return 1\n","    elif row_label == 'Green':\n","        return 2\n","    elif row_label == 'Yellow':\n","        return 3\n","    elif row_label == 'Red':\n","        return 4\n","    else:\n","        return 0\n","```\n"]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"g9C1hVwv-S2f"},"source":["This script was originally from: https://github.com/datitran/raccoon_dataset"]},{"cell_type":"markdown","metadata":{"id":"Lh7jnOeGBRzK","colab_type":"text"},"source":["INPUTS: \n","1. CSV files\n","2. Image principal folder\n","\n","OUTPUT:\n","1. record file, saved in ../record_files/"]},{"cell_type":"code","metadata":{"id":"nSajdNJnYTfE","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS\n","%mkdir '/content/drive/My Drive/SMART_SCOOTER/record_files'\n","%mkdir '/content/drive/My Drive/SMART_SCOOTER/record_files/TL'\n","%mkdir '/content/drive/My Drive/SMART_SCOOTER/record_files/CONE'\n","!python generate_tfrecord.py --csv_input='/content/drive/My Drive/SMART_SCOOTER/annotations/TL/train_csv_annotations/train_labels.csv' --image_dir='/content/drive/My Drive/SMART_SCOOTER/images/TL' --output_path='/content/drive/My Drive/SMART_SCOOTER/record_files/TL/train.record'\n","!python generate_tfrecord.py --csv_input='/content/drive/My Drive/SMART_SCOOTER/annotations/TL/test_csv_annotations/test_labels.csv' --image_dir='/content/drive/My Drive/SMART_SCOOTER/images/TL' --output_path='/content/drive/My Drive/SMART_SCOOTER/record_files/TL/test.record'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"CBjW0hJWUjQo"},"source":["If already have record files and run this, files will be overwritten"]},{"cell_type":"markdown","metadata":{"id":"RyIMLmYA-kiL","colab_type":"text"},"source":["##Create labelmap, ckpt and config files\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"95MYGTJECDF1","colab_type":"text"},"source":["###Labelmap.pbtxt"]},{"cell_type":"markdown","metadata":{"id":"0bI9YpC6CGoh","colab_type":"text"},"source":["This file tells the training which labels (classes) we want as output in the model. We are going to \"attach\" this file in the config"]},{"cell_type":"markdown","metadata":{"id":"JhKIqwkTCYRO","colab_type":"text"},"source":["We find this file in: ```SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/labelmap```\n","\n","\n","```\n","item {\n","  id: 1\n","  name: 'off'\n","}\n","\n","item {\n","  id: 2\n","  name: 'Green'\n","}\n","\n","item {\n","  id: 3\n","  name: 'Yellow'\n","}\n","\n","item {\n","  id: 4\n","  name: 'Red'\n","}\n","```\n","\n"]},{"cell_type":"markdown","metadata":{"id":"mCMIMwMjDKgY","colab_type":"text"},"source":["###model.ckpt"]},{"cell_type":"markdown","metadata":{"id":"BvaOtaaokDM6","colab_type":"text"},"source":["We can download any pre-trained Object detection model from tensorflow with the code below. In this case we are downloading the ssdlite_mobilenet_v2"]},{"cell_type":"code","metadata":{"id":"m61blLNHkEqC","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/\n","!wget http://download.tensorflow.org/models/object_detection/ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz\n","!tar -xvf ssdlite_mobilenet_v2_coco_2018_05_09.tar.gz "],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_LZUGf7lBI3c","colab_type":"text"},"source":["From this downloaded model we will use the pretrained model: \n","```model.ckpt```\n","This model has two parts:\n","1. Mobilenet for feature extraction model\n","2. SSDlite_v2 for finetuning\n","\n","In the training process we will import all the pretrained mobilenet part, and we will modify the SSD part (finetunning).\n"]},{"cell_type":"markdown","metadata":{"id":"V59esfQpC-fw","colab_type":"text"},"source":["###Config"]},{"cell_type":"markdown","metadata":{"id":"xP3Ik6oTsLI_","colab_type":"text"},"source":["The config file tells the training how we are going to train the model and with which files.\n","\n","In this case the config file is also originally from the ssdlite_mobilenet_v2 model. But with the next modifications:\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ClhsOPMcpd0f","colab_type":"text"},"source":["1. `num_classes=4`\n","\n","2. `set anchor boxes aspect ratios`\n","\n","3. `fine_tune_checkpoint: \"/content/drive/My Drive/SMART_SCOOTER/ssdlite_mobilenet_v2_coco_2018_05_09/model.ckpt\"`\n","\n","  or\n","\n","  `fine_tune_checkpoint: \"/content/drive/My Drive/SMART_SCOOTER/new_models/TL_XX/model.ckpt-XXXX\"`\n","\n","3. `set batch_size=24 or 32` number of images trained on every step\n","\n","4. ```\n","learning_rate: {\n","        exponential_decay_learning_rate {\n","          initial_learning_rate: 0.004\n","          decay_steps: 800720 \n","          decay_factor: 0.95 \n","        }```\n","https://www.tensorflow.org/api_docs/python/tf/compat/v1/train/exponential_decay\n","5. `num_steps=10000-15000`\n","\n","4. `input_path: \"/content/drive/My Drive/SMART_SCOOTER/record_files/train.record\"`\n","\n","5. `input_path: \"/content/drive/My Drive/SMART_SCOOTER/record_files/test.record\"`\n","\n","6. `label_map_path: \"/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/labelmap/TL.pbtxt\"`\n","\n","7. ```\n","image_resizer {\n","      fixed_shape_resizer {\n","        height: 300\n","        width: 300\n","      }\n","```\n","8. `num_examples: 40 (number of detections in test_csv_annotation)`\n","\n","\n","Trainings:\n","\n","- TL_v2: 10k steps, i_lr=0.004, d_s=800720,d_f=0.96, b_s=24\n","    \n","    Loss_aprox=2-3\n","- TL_v3: 50k steps, i_lr=0.008, d_s=20000, d_f=0.5, b_s=32\n","    \n","    Loss_aprox="]},{"cell_type":"markdown","metadata":{"id":"FmH5B8gpZYtQ","colab_type":"text"},"source":["We will find the config in: `SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config`"]},{"cell_type":"markdown","metadata":{"id":"4Kp8q-1PA0ot","colab_type":"text"},"source":["##Training\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9Dcy2OKfumnj","colab_type":"text"},"source":["We can train with two files:\n","1. train.py (train_dir).\n","  Is found in the legacy folder, so we have to copy it to the\n","object_detection folder for commodity.\n","\n","2. model_main.py (model_dir), is in the object_detection folder, so we will have both scripts in the same folder.\n","\n","Although we get same speed and accuracy, it is preferable to use model_main because we can evaluate at the same time. But if we get errors, we have to use train.py. \n","\n","We can later see the process in the tensorboard.\n","\n"," "]},{"cell_type":"code","metadata":{"id":"zVZ0x484uqP6","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/legacy\n","%cp train.py ..\n","%mkdir '/content/drive/My Drive/SMART_SCOOTER/training/'\n","%mkdir '/content/drive/My Drive/SMART_SCOOTER/training/TL'\n","%cd .."],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xKs9JWt09IHA","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/\n","#!python train.py --logtostderr --train_dir='/content/drive/My Drive/SMART_SCOOTER/training/TL/TL_v2' --pipeline_config_path='/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config/TL.config'\n","!python model_main.py --logtostderr --model_dir='/content/drive/My Drive/SMART_SCOOTER/training/TL/TL_v2' --pipeline_config_path='/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config/TL.config'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RQ72Qg8XlYRQ","colab_type":"text"},"source":["##Export your inference graph\n","\n","---\n","\n"]},{"cell_type":"markdown","metadata":{"id":"oyY2rYVvk-SW","colab_type":"text"},"source":["To export the new model, we just have to run this cript specifying:\n","- where the config, used for the training, is \n","- which input_type do we want for the inference: image_tensor (blob image)\n","- The trained model checkpoint we want to use\n","- The output directory where we want to save the new model"]},{"cell_type":"code","metadata":{"id":"00CU-oBHlYgd","colab_type":"code","outputId":"b3b2cfe2-c758-4287-e38a-adcad789e88f","executionInfo":{"status":"ok","timestamp":1585074828878,"user_tz":-60,"elapsed":17109,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n","!python export_inference_graph.py --input_type image_tensor  --pipeline_config_path '/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config/TL.config'   --trained_checkpoint_prefix '/content/drive/My Drive/SMART_SCOOTER/training/TL/TL_v2/model.ckpt-9785'   --output_directory '/content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2'"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n","WARNING:tensorflow:\n","The TensorFlow contrib module will not be included in TensorFlow 2.0.\n","For more information, please see:\n","  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n","  * https://github.com/tensorflow/addons\n","  * https://github.com/tensorflow/io (for I/O related ops)\n","If you depend on functionality not listed there, please file an issue.\n","\n","WARNING:tensorflow:From export_inference_graph.py:162: The name tf.app.run is deprecated. Please use tf.compat.v1.app.run instead.\n","\n","WARNING:tensorflow:From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0324 18:33:36.084408 140139497539456 module_wrapper.py:139] From export_inference_graph.py:145: The name tf.gfile.GFile is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","W0324 18:33:36.091981 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:402: The name tf.gfile.MakeDirs is deprecated. Please use tf.io.gfile.makedirs instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","W0324 18:33:36.096362 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:121: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","W0324 18:33:36.130480 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/core/preprocessor.py:2937: The name tf.image.resize_images is deprecated. Please use tf.image.resize instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","W0324 18:33:36.161268 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/meta_architectures/ssd_meta_arch.py:589: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","W0324 18:33:36.161561 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/meta_architectures/ssd_meta_arch.py:597: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n","\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","W0324 18:33:36.164381 140139497539456 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/contrib/layers/python/layers/layers.py:1057: Layer.apply (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please use `layer.__call__` method instead.\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","W0324 18:33:38.583886 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/core/anchor_generator.py:171: The name tf.assert_equal is deprecated. Please use tf.compat.v1.assert_equal instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","W0324 18:33:38.595758 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/predictors/convolutional_box_predictor.py:150: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n","\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0324 18:33:38.596004 140139497539456 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0324 18:33:38.688363 140139497539456 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0324 18:33:38.783905 140139497539456 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0324 18:33:38.877155 140139497539456 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0324 18:33:38.964956 140139497539456 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","INFO:tensorflow:depth of additional conv before box predictor: 0\n","I0324 18:33:39.056003 140139497539456 convolutional_box_predictor.py:151] depth of additional conv before box predictor: 0\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","W0324 18:33:39.388681 140139497539456 deprecation.py:323] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/core/post_processing.py:581: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","W0324 18:33:39.831412 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:278: The name tf.add_to_collection is deprecated. Please use tf.compat.v1.add_to_collection instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","W0324 18:33:39.831729 140139497539456 deprecation.py:323] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:383: get_or_create_global_step (from tensorflow.contrib.framework.python.ops.variables) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Please switch to tf.train.get_or_create_global_step\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","W0324 18:33:39.835249 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:415: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","W0324 18:33:39.835447 140139497539456 deprecation.py:323] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:539: print_model_analysis (from tensorflow.contrib.tfprof.model_analyzer) is deprecated and will be removed after 2018-01-01.\n","Instructions for updating:\n","Use `tf.profiler.profile(graph, run_meta, op_log, cmd, options)`. Build `options` with `tf.profiler.ProfileOptionBuilder`. See README.md for details\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","W0324 18:33:39.836474 140139497539456 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/profiler/internal/flops_registry.py:142: tensor_shape_from_node_def_name (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.tensor_shape_from_node_def_name`\n","155 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              0\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   name\n","-account_type_regexes       _trainable_variables\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     params\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","param: Number of parameters (in the Variable).\n","\n","Profile:\n","node name | # parameters\n","_TFProfRoot (--/3.04m params)\n","  BoxPredictor_0 (--/25.95k params)\n","    BoxPredictor_0/BoxEncodingPredictor (--/6.92k params)\n","      BoxPredictor_0/BoxEncodingPredictor/biases (12, 12/12 params)\n","      BoxPredictor_0/BoxEncodingPredictor/weights (1x1x576x12, 6.91k/6.91k params)\n","    BoxPredictor_0/BoxEncodingPredictor_depthwise (--/5.18k params)\n","      BoxPredictor_0/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_0/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","    BoxPredictor_0/ClassPredictor (--/8.65k params)\n","      BoxPredictor_0/ClassPredictor/biases (15, 15/15 params)\n","      BoxPredictor_0/ClassPredictor/weights (1x1x576x15, 8.64k/8.64k params)\n","    BoxPredictor_0/ClassPredictor_depthwise (--/5.18k params)\n","      BoxPredictor_0/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_0/ClassPredictor_depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","  BoxPredictor_1 (--/92.21k params)\n","    BoxPredictor_1/BoxEncodingPredictor (--/30.74k params)\n","      BoxPredictor_1/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_1/BoxEncodingPredictor/weights (1x1x1280x24, 30.72k/30.72k params)\n","    BoxPredictor_1/BoxEncodingPredictor_depthwise (--/11.52k params)\n","      BoxPredictor_1/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_1/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x1280x1, 11.52k/11.52k params)\n","    BoxPredictor_1/ClassPredictor (--/38.43k params)\n","      BoxPredictor_1/ClassPredictor/biases (30, 30/30 params)\n","      BoxPredictor_1/ClassPredictor/weights (1x1x1280x30, 38.40k/38.40k params)\n","    BoxPredictor_1/ClassPredictor_depthwise (--/11.52k params)\n","      BoxPredictor_1/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_1/ClassPredictor_depthwise/depthwise_weights (3x3x1280x1, 11.52k/11.52k params)\n","  BoxPredictor_2 (--/36.92k params)\n","    BoxPredictor_2/BoxEncodingPredictor (--/12.31k params)\n","      BoxPredictor_2/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_2/BoxEncodingPredictor/weights (1x1x512x24, 12.29k/12.29k params)\n","    BoxPredictor_2/BoxEncodingPredictor_depthwise (--/4.61k params)\n","      BoxPredictor_2/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_2/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","    BoxPredictor_2/ClassPredictor (--/15.39k params)\n","      BoxPredictor_2/ClassPredictor/biases (30, 30/30 params)\n","      BoxPredictor_2/ClassPredictor/weights (1x1x512x30, 15.36k/15.36k params)\n","    BoxPredictor_2/ClassPredictor_depthwise (--/4.61k params)\n","      BoxPredictor_2/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_2/ClassPredictor_depthwise/depthwise_weights (3x3x512x1, 4.61k/4.61k params)\n","  BoxPredictor_3 (--/18.49k params)\n","    BoxPredictor_3/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_3/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_3/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_3/BoxEncodingPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_3/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_3/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","    BoxPredictor_3/ClassPredictor (--/7.71k params)\n","      BoxPredictor_3/ClassPredictor/biases (30, 30/30 params)\n","      BoxPredictor_3/ClassPredictor/weights (1x1x256x30, 7.68k/7.68k params)\n","    BoxPredictor_3/ClassPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_3/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_3/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","  BoxPredictor_4 (--/18.49k params)\n","    BoxPredictor_4/BoxEncodingPredictor (--/6.17k params)\n","      BoxPredictor_4/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_4/BoxEncodingPredictor/weights (1x1x256x24, 6.14k/6.14k params)\n","    BoxPredictor_4/BoxEncodingPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_4/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_4/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","    BoxPredictor_4/ClassPredictor (--/7.71k params)\n","      BoxPredictor_4/ClassPredictor/biases (30, 30/30 params)\n","      BoxPredictor_4/ClassPredictor/weights (1x1x256x30, 7.68k/7.68k params)\n","    BoxPredictor_4/ClassPredictor_depthwise (--/2.30k params)\n","      BoxPredictor_4/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_4/ClassPredictor_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","  BoxPredictor_5 (--/9.27k params)\n","    BoxPredictor_5/BoxEncodingPredictor (--/3.10k params)\n","      BoxPredictor_5/BoxEncodingPredictor/biases (24, 24/24 params)\n","      BoxPredictor_5/BoxEncodingPredictor/weights (1x1x128x24, 3.07k/3.07k params)\n","    BoxPredictor_5/BoxEncodingPredictor_depthwise (--/1.15k params)\n","      BoxPredictor_5/BoxEncodingPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_5/BoxEncodingPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","    BoxPredictor_5/ClassPredictor (--/3.87k params)\n","      BoxPredictor_5/ClassPredictor/biases (30, 30/30 params)\n","      BoxPredictor_5/ClassPredictor/weights (1x1x128x30, 3.84k/3.84k params)\n","    BoxPredictor_5/ClassPredictor_depthwise (--/1.15k params)\n","      BoxPredictor_5/ClassPredictor_depthwise/BatchNorm (--/0 params)\n","      BoxPredictor_5/ClassPredictor_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","  FeatureExtractor (--/2.84m params)\n","    FeatureExtractor/MobilenetV2 (--/2.84m params)\n","      FeatureExtractor/MobilenetV2/Conv (--/864 params)\n","        FeatureExtractor/MobilenetV2/Conv/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv/weights (3x3x3x32, 864/864 params)\n","      FeatureExtractor/MobilenetV2/Conv_1 (--/409.60k params)\n","        FeatureExtractor/MobilenetV2/Conv_1/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/Conv_1/weights (1x1x320x1280, 409.60k/409.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv (--/800 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/depthwise (--/288 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/depthwise/depthwise_weights (3x3x32x1, 288/288 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv/project (--/512 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv/project/weights (1x1x32x16, 512/512 params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_1 (--/4.70k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise (--/864 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/depthwise/depthwise_weights (3x3x96x1, 864/864 params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/expand (--/1.54k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/expand/weights (1x1x16x96, 1.54k/1.54k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_1/project (--/2.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_1/project/weights (1x1x96x24, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_10 (--/64.90k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_10/project (--/36.86k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_10/project/weights (1x1x384x96, 36.86k/36.86k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_11 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_11/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_11/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_12 (--/115.78k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_12/project (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_12/project/weights (1x1x576x96, 55.30k/55.30k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_13 (--/152.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise (--/5.18k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/depthwise/depthwise_weights (3x3x576x1, 5.18k/5.18k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/expand (--/55.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/expand/weights (1x1x96x576, 55.30k/55.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_13/project (--/92.16k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_13/project/weights (1x1x576x160, 92.16k/92.16k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_14 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_14/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_14/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_15 (--/315.84k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_15/project (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_15/project/weights (1x1x960x160, 153.60k/153.60k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_16 (--/469.44k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise (--/8.64k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/depthwise/depthwise_weights (3x3x960x1, 8.64k/8.64k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/expand (--/153.60k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/expand/weights (1x1x160x960, 153.60k/153.60k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_16/project (--/307.20k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_16/project/weights (1x1x960x320, 307.20k/307.20k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_2 (--/8.21k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_2/project (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_2/project/weights (1x1x144x24, 3.46k/3.46k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_3 (--/9.36k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise (--/1.30k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/depthwise/depthwise_weights (3x3x144x1, 1.30k/1.30k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/expand (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/expand/weights (1x1x24x144, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_3/project (--/4.61k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_3/project/weights (1x1x144x32, 4.61k/4.61k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_4 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_4/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_4/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_5 (--/14.02k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_5/project (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_5/project/weights (1x1x192x32, 6.14k/6.14k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_6 (--/20.16k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise (--/1.73k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/depthwise/depthwise_weights (3x3x192x1, 1.73k/1.73k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/expand (--/6.14k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/expand/weights (1x1x32x192, 6.14k/6.14k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_6/project (--/12.29k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_6/project/weights (1x1x192x64, 12.29k/12.29k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_7 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_7/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_7/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_8 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_8/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_8/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/expanded_conv_9 (--/52.61k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise (--/3.46k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/depthwise/depthwise_weights (3x3x384x1, 3.46k/3.46k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/expand (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/expand/weights (1x1x64x384, 24.58k/24.58k params)\n","        FeatureExtractor/MobilenetV2/expanded_conv_9/project (--/24.58k params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/BatchNorm (--/0 params)\n","          FeatureExtractor/MobilenetV2/expanded_conv_9/project/weights (1x1x384x64, 24.58k/24.58k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256 (--/327.68k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_2_1x1_256/weights (1x1x1280x256, 327.68k/327.68k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128 (--/65.54k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_3_1x1_128/weights (1x1x512x128, 65.54k/65.54k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_4_1x1_128/weights (1x1x256x128, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64 (--/16.38k params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_1_Conv2d_5_1x1_64/weights (1x1x256x64, 16.38k/16.38k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512 (--/131.07k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512/weights (1x1x256x512, 131.07k/131.07k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise (--/2.30k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_2_3x3_s2_512_depthwise/depthwise_weights (3x3x256x1, 2.30k/2.30k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_3_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256 (--/32.77k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256/weights (1x1x128x256, 32.77k/32.77k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise (--/1.15k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_4_3x3_s2_256_depthwise/depthwise_weights (3x3x128x1, 1.15k/1.15k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128 (--/8.19k params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128/weights (1x1x64x128, 8.19k/8.19k params)\n","      FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise (--/576 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/BatchNorm (--/0 params)\n","        FeatureExtractor/MobilenetV2/layer_19_2_Conv2d_5_3x3_s2_128_depthwise/depthwise_weights (3x3x64x1, 576/576 params)\n","\n","======================End of Report==========================\n","155 ops no flops stats due to incomplete shapes.\n","Parsing Inputs...\n","Incomplete shape.\n","\n","=========================Options=============================\n","-max_depth                  10000\n","-min_bytes                  0\n","-min_peak_bytes             0\n","-min_residual_bytes         0\n","-min_output_bytes           0\n","-min_micros                 0\n","-min_accelerator_micros     0\n","-min_cpu_micros             0\n","-min_params                 0\n","-min_float_ops              1\n","-min_occurrence             0\n","-step                       -1\n","-order_by                   float_ops\n","-account_type_regexes       .*\n","-start_name_regexes         .*\n","-trim_name_regexes          .*BatchNorm.*,.*Initializer.*,.*Regularizer.*,.*BiasAdd.*\n","-show_name_regexes          .*\n","-hide_name_regexes          \n","-account_displayed_op_only  true\n","-select                     float_ops\n","-output                     stdout:\n","\n","==================Model Analysis Report======================\n","Incomplete shape.\n","\n","Doc:\n","scope: The nodes in the model graph are organized by their names, which is hierarchical like filesystem.\n","flops: Number of float operations. Note: Please read the implementation for the math behind it.\n","\n","Profile:\n","node name | # float_ops\n","_TFProfRoot (--/13.72k flops)\n","  MultipleGridAnchorGenerator/mul_20 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/sub (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_19 (2.17k/2.17k flops)\n","  MultipleGridAnchorGenerator/mul_27 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/sub_1 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_28 (1.20k/1.20k flops)\n","  MultipleGridAnchorGenerator/mul_21 (1.08k/1.08k flops)\n","  MultipleGridAnchorGenerator/mul_29 (600/600 flops)\n","  MultipleGridAnchorGenerator/sub_2 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_35 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_36 (300/300 flops)\n","  MultipleGridAnchorGenerator/mul_37 (150/150 flops)\n","  MultipleGridAnchorGenerator/sub_3 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_44 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_43 (108/108 flops)\n","  MultipleGridAnchorGenerator/mul_45 (54/54 flops)\n","  MultipleGridAnchorGenerator/sub_4 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_51 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_52 (48/48 flops)\n","  MultipleGridAnchorGenerator/mul_53 (24/24 flops)\n","  MultipleGridAnchorGenerator/mul_18 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_17 (19/19 flops)\n","  MultipleGridAnchorGenerator/mul_60 (12/12 flops)\n","  MultipleGridAnchorGenerator/sub_5 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_59 (12/12 flops)\n","  MultipleGridAnchorGenerator/mul_25 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_26 (10/10 flops)\n","  MultipleGridAnchorGenerator/mul_40 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_30 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_61 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_46 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_47 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_48 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_56 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_55 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_54 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_39 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_38 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_32 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_31 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_24 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_23 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_22 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_19 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_18 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_17 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_15 (6/6 flops)\n","  MultipleGridAnchorGenerator/truediv_16 (6/6 flops)\n","  MultipleGridAnchorGenerator/mul_34 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_33 (5/5 flops)\n","  MultipleGridAnchorGenerator/mul_42 (3/3 flops)\n","  MultipleGridAnchorGenerator/truediv_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_14 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_15 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_16 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_41 (3/3 flops)\n","  MultipleGridAnchorGenerator/mul_49 (2/2 flops)\n","  MultipleGridAnchorGenerator/mul_50 (2/2 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField_1/Equal (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/SortByField/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_19 (1/1 flops)\n","  Preprocessor/map/while/Less_1 (1/1 flops)\n","  Preprocessor/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/ones/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_9 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_8 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_7 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_6 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_5 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_4 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_18 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_17 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_16 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_15 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_14 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_13 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_12 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_11 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_10 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/PadOrClipBoxList/sub_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/Minimum (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_58 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_57 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_13 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_12 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_11 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_10 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul_1 (1/1 flops)\n","  MultipleGridAnchorGenerator/mul (1/1 flops)\n","  MultipleGridAnchorGenerator/assert_equal_1/Equal (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_3 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_2 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Greater (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/truediv (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/ChangeCoordinateFrame/sub (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/Less_1 (1/1 flops)\n","  Postprocessor/BatchMultiClassNonMaxSuppression/map/while/MultiClassNonMaxSuppression/Minimum_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_9 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_8 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_7 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_6 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_5 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_4 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_3 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_2 (1/1 flops)\n","  MultipleGridAnchorGenerator/truediv_13 (1/1 flops)\n","\n","======================End of Report==========================\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","W0324 18:33:41.076466 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:432: The name tf.train.Saver is deprecated. Please use tf.compat.v1.train.Saver instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","W0324 18:33:42.073867 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:342: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n","\n","2020-03-24 18:33:42.075349: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcuda.so.1\n","2020-03-24 18:33:42.091896: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.092445: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-03-24 18:33:42.092745: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-24 18:33:42.094959: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-24 18:33:42.097161: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-03-24 18:33:42.097528: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-03-24 18:33:42.110547: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-03-24 18:33:42.119794: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-03-24 18:33:42.133590: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-03-24 18:33:42.133792: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.134426: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.134981: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-03-24 18:33:42.141277: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2300000000 Hz\n","2020-03-24 18:33:42.141534: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x3264d80 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n","2020-03-24 18:33:42.141567: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n","2020-03-24 18:33:42.242710: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.243491: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x32652c0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n","2020-03-24 18:33:42.243529: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Tesla P100-PCIE-16GB, Compute Capability 6.0\n","2020-03-24 18:33:42.243809: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.244382: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-03-24 18:33:42.244468: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-24 18:33:42.244486: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-24 18:33:42.244503: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-03-24 18:33:42.244518: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-03-24 18:33:42.244532: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-03-24 18:33:42.244548: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-03-24 18:33:42.244565: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-03-24 18:33:42.244683: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.245287: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.245811: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-03-24 18:33:42.245888: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-24 18:33:42.247142: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-03-24 18:33:42.247173: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-03-24 18:33:42.247184: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-03-24 18:33:42.247332: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.248009: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:42.248567: W tensorflow/core/common_runtime/gpu/gpu_bfc_allocator.cc:39] Overriding allow_growth setting because the TF_FORCE_GPU_ALLOW_GROWTH environment variable is set. Original config value was 0.\n","2020-03-24 18:33:42.248606: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/SMART_SCOOTER/training/TL/TL_v2/model.ckpt-9785\n","I0324 18:33:42.251965 140139497539456 saver.py:1284] Restoring parameters from /content/drive/My Drive/SMART_SCOOTER/training/TL/TL_v2/model.ckpt-9785\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","W0324 18:33:44.499081 140139497539456 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/tools/freeze_graph.py:127: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use standard file APIs to check for files with this prefix.\n","2020-03-24 18:33:45.226978: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:45.227585: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-03-24 18:33:45.227720: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-24 18:33:45.227750: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-24 18:33:45.227775: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-03-24 18:33:45.227800: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-03-24 18:33:45.227823: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-03-24 18:33:45.227845: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-03-24 18:33:45.227867: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-03-24 18:33:45.227984: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:45.228556: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:45.229085: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-03-24 18:33:45.229134: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-03-24 18:33:45.229148: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-03-24 18:33:45.229158: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-03-24 18:33:45.229291: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:45.229927: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:45.230454: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","INFO:tensorflow:Restoring parameters from /content/drive/My Drive/SMART_SCOOTER/training/TL/TL_v2/model.ckpt-9785\n","I0324 18:33:45.232282 140139497539456 saver.py:1284] Restoring parameters from /content/drive/My Drive/SMART_SCOOTER/training/TL/TL_v2/model.ckpt-9785\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","W0324 18:33:46.000875 140139497539456 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/tools/freeze_graph.py:233: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n","WARNING:tensorflow:From /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","W0324 18:33:46.001157 140139497539456 deprecation.py:323] From /tensorflow-1.15.0/python3.6/tensorflow_core/python/framework/graph_util_impl.py:277: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use `tf.compat.v1.graph_util.extract_sub_graph`\n","INFO:tensorflow:Froze 404 variables.\n","I0324 18:33:46.456286 140139497539456 graph_util_impl.py:334] Froze 404 variables.\n","INFO:tensorflow:Converted 404 variables to const ops.\n","I0324 18:33:46.546549 140139497539456 graph_util_impl.py:394] Converted 404 variables to const ops.\n","2020-03-24 18:33:46.714443: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:46.715050: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1618] Found device 0 with properties: \n","name: Tesla P100-PCIE-16GB major: 6 minor: 0 memoryClockRate(GHz): 1.3285\n","pciBusID: 0000:00:04.0\n","2020-03-24 18:33:46.715154: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudart.so.10.1\n","2020-03-24 18:33:46.715185: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcublas.so.10\n","2020-03-24 18:33:46.715206: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcufft.so.10\n","2020-03-24 18:33:46.715228: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcurand.so.10\n","2020-03-24 18:33:46.715265: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusolver.so.10\n","2020-03-24 18:33:46.715287: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcusparse.so.10\n","2020-03-24 18:33:46.715308: I tensorflow/stream_executor/platform/default/dso_loader.cc:44] Successfully opened dynamic library libcudnn.so.7\n","2020-03-24 18:33:46.715429: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:46.716043: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:46.716529: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1746] Adding visible gpu devices: 0\n","2020-03-24 18:33:46.716574: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1159] Device interconnect StreamExecutor with strength 1 edge matrix:\n","2020-03-24 18:33:46.716593: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1165]      0 \n","2020-03-24 18:33:46.716603: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1178] 0:   N \n","2020-03-24 18:33:46.716740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:46.717317: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:983] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n","2020-03-24 18:33:46.717860: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1304] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 15216 MB memory) -> physical GPU (device: 0, name: Tesla P100-PCIE-16GB, pci bus id: 0000:00:04.0, compute capability: 6.0)\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","W0324 18:33:47.140118 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:306: The name tf.saved_model.builder.SavedModelBuilder is deprecated. Please use tf.compat.v1.saved_model.builder.SavedModelBuilder instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","W0324 18:33:47.143385 140139497539456 deprecation.py:323] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:309: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","W0324 18:33:47.143933 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:315: The name tf.saved_model.signature_def_utils.build_signature_def is deprecated. Please use tf.compat.v1.saved_model.signature_def_utils.build_signature_def instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","W0324 18:33:47.144150 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:318: The name tf.saved_model.signature_constants.PREDICT_METHOD_NAME is deprecated. Please use tf.saved_model.PREDICT_METHOD_NAME instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","W0324 18:33:47.144433 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:323: The name tf.saved_model.tag_constants.SERVING is deprecated. Please use tf.saved_model.SERVING instead.\n","\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","W0324 18:33:47.144610 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/exporter.py:325: The name tf.saved_model.signature_constants.DEFAULT_SERVING_SIGNATURE_DEF_KEY is deprecated. Please use tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY instead.\n","\n","INFO:tensorflow:No assets to save.\n","I0324 18:33:47.144953 140139497539456 builder_impl.py:640] No assets to save.\n","INFO:tensorflow:No assets to write.\n","I0324 18:33:47.145081 140139497539456 builder_impl.py:460] No assets to write.\n","INFO:tensorflow:SavedModel written to: /content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2/saved_model/saved_model.pb\n","I0324 18:33:47.452754 140139497539456 builder_impl.py:425] SavedModel written to: /content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2/saved_model/saved_model.pb\n","WARNING:tensorflow:From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","W0324 18:33:47.480752 140139497539456 module_wrapper.py:139] From /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/utils/config_util.py:188: The name tf.gfile.Open is deprecated. Please use tf.io.gfile.GFile instead.\n","\n","INFO:tensorflow:Writing pipeline config file to /content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2/pipeline.config\n","I0324 18:33:47.481004 140139497539456 config_util.py:190] Writing pipeline config file to /content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2/pipeline.config\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"2fwi02fdrsdy","colab_type":"text"},"source":["Create files to run the network on opencv. \n","In other words, we need to create a graph.pbtxt to make the inference later in the OpenCv network. To do this we have to use 2 files that we already have in SmartScooter:\n","1. tf_text_graph_ssd.py\n","2. tf_text_graph_common.py (used inside tf_text_graph_ssd.py)\n","\n","We will just run the first one, with the frozen_inference_graph.pb as input with the config file too.\n","\n","We will save the graph.pbtxt in the new_model folder."]},{"cell_type":"code","metadata":{"id":"1ELaYAZPo_4p","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS\n","!python tf_text_graph_ssd.py --input '/content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2/frozen_inference_graph.pb' --config '/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/config/TL.config' --output '/content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2/graph.pbtxt'"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"v48gUvN1o-jG","colab_type":"text"},"source":["We have to replace "]},{"cell_type":"markdown","metadata":{"id":"Oed6NEhfox74","colab_type":"text"},"source":["Zip the model"]},{"cell_type":"code","metadata":{"id":"Luz9YZe5oyns","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER\n","!zip -r TL_V1.zip new_models/TL_v2"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oVp3Ti0iofug","colab_type":"text"},"source":["##Test your inference graph\n","\n","---\n","\n","\n"]},{"cell_type":"code","metadata":{"id":"DZ9K_ofDyrE6","colab_type":"code","outputId":"ef11a243-4350-40ef-8aa0-0d043023cbd0","executionInfo":{"status":"ok","timestamp":1584624174230,"user_tz":-60,"elapsed":1367,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"4kFYqGw89qS2","colab_type":"code","outputId":"563ac200-eca6-48f5-dc75-6c6db9a66c25","executionInfo":{"status":"ok","timestamp":1584625481304,"user_tz":-60,"elapsed":799,"user":{"displayName":"Smart Scooter","photoUrl":"","userId":"15428351325187719454"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/utils\n","# This is needed since the notebook is stored in the object_detection folder.\n","\n","sys.path.append(\"..\")\n","import utils\n","#sys.path.append(\"..\")\n","import label_map_util\n","\n","import visualization_utils as vis_util"],"execution_count":0,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/utils\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"Jo1zLXX4uKW5","colab_type":"code","colab":{}},"source":["%cd /content/drive/My Drive/SMART_SCOOTER/models/research/object_detection/\n","import numpy as np\n","import os\n","import six.moves.urllib as urllib\n","import sys\n","import tarfile\n","import tensorflow as tf\n","import zipfile\n","\n","from collections import defaultdict\n","from io import StringIO\n","from matplotlib import pyplot as plt\n","from PIL import Image\n","\n","# This is needed to display the images.\n","%matplotlib inline\n","\n","\n","# Path to frozen detection graph. This is the actual model that is used for the object detection.\n","PATH_TO_CKPT = '/content/drive/My Drive/SMART_SCOOTER/new_models/TL/TL_v2/frozen_inference_graph.pb'\n","\n","# List of the strings that is used to add correct label for each box.\n","PATH_TO_LABELS = os.path.join('/content/drive/My Drive/SMART_SCOOTER/SmartScooter/TRAFFIC_LIGHTS/TL_W_COLORS/labelmap', 'TL.pbtxt')\n","\n","NUM_CLASSES = 4\n","\n","detection_graph = tf.Graph()\n","with detection_graph.as_default():\n","    od_graph_def = tf.GraphDef()\n","    with tf.gfile.GFile(PATH_TO_CKPT, 'rb') as fid:\n","        serialized_graph = fid.read()\n","        od_graph_def.ParseFromString(serialized_graph)\n","        tf.import_graph_def(od_graph_def, name='')\n","\n","\n","\n","label_map = label_map_util.load_labelmap(PATH_TO_LABELS)\n","categories = label_map_util.convert_label_map_to_categories(label_map, max_num_classes=NUM_CLASSES, use_display_name=True)\n","category_index = label_map_util.create_category_index(categories)\n","\n","def load_image_into_numpy_array(image):\n","    (im_width, im_height) = image.size\n","    return np.array(image.getdata()).reshape(\n","        (im_height, im_width, 3)).astype(np.uint8)\n","# If you want to test the code with your images, just add path to the images to the TEST_IMAGE_PATHS.\n","PATH_TO_TEST_IMAGES_DIR = '/content/drive/My Drive/SMART_SCOOTER/images/TL/new_train'\n","TEST_IMAGE_PATHS = [ os.path.join(PATH_TO_TEST_IMAGES_DIR, '{}'.format(i)) for i in os.listdir('/content/drive/My Drive/SMART_SCOOTER/images/TL/new_train') ]\n","\n","# Size, in inches, of the output images.\n","IMAGE_SIZE = (12, 8)\n","c=0\n","with detection_graph.as_default():\n","    with tf.Session(graph=detection_graph) as sess:\n","        # Definite input and output Tensors for detection_graph\n","        image_tensor = detection_graph.get_tensor_by_name('image_tensor:0')\n","        # Each box represents a part of the image where a particular object was detected.\n","        detection_boxes = detection_graph.get_tensor_by_name('detection_boxes:0')\n","        # Each score represent how level of confidence for each of the objects.\n","        # Score is shown on the result image, together with the class label.\n","        detection_scores = detection_graph.get_tensor_by_name('detection_scores:0')\n","        detection_classes = detection_graph.get_tensor_by_name('detection_classes:0')\n","        num_detections = detection_graph.get_tensor_by_name('num_detections:0')\n","        for image_path in TEST_IMAGE_PATHS:\n","         if c<6: \n","          if image_path.endswith('.jpg'):\n","            image = Image.open(image_path)\n","            # the array based representation of the image will be used later in order to prepare the\n","            # result image with boxes and labels on it.\n","            image_np = load_image_into_numpy_array(image)\n","            # Expand dimensions since the model expects images to have shape: [1, None, None, 3]\n","            image_np_expanded = np.expand_dims(image_np, axis=0)\n","            # Actual detection.\n","            (boxes, scores, classes, num) = sess.run(\n","                [detection_boxes, detection_scores, detection_classes, num_detections],\n","                feed_dict={image_tensor: image_np_expanded})\n","            # Visualization of the results of a detection.\n","            vis_util.visualize_boxes_and_labels_on_image_array(\n","                image_np,\n","                np.squeeze(boxes),\n","                np.squeeze(classes).astype(np.int32),\n","                np.squeeze(scores),\n","                category_index,\n","                use_normalized_coordinates=True,\n","                line_thickness=8)\n","            plt.figure(figsize=IMAGE_SIZE)\n","            plt.imshow(image_np)\n","            c+=1"],"execution_count":0,"outputs":[]}]}